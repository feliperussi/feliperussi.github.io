---
---

@string{aps = {American Physical Society,}}

@inproceedings{arias-russi-etal-2025-bridging,
  abbr      = {NAACL 2025},
  title     = {Bridging the Gap in Health Literacy: Harnessing the Power of Large Language Models to Generate Plain Language Summaries from Biomedical Texts},
  author    = {Arias-Russi, Andr{\'e}s  and
               Salazar-Lara, Carolina  and
               Manrique, Rub{\'e}n},
  editor    = {Ananiadou, Sophia  and
               Demner-Fushman, Dina  and
               Gupta, Deepak  and
               Thompson, Paul},
  booktitle = {Proceedings of the Second Workshop on Patient-Oriented Language Processing (CL4Health)},
  month     = may,
  year      = {2025},
  address   = {Albuquerque, New Mexico},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2025.cl4health-1.23/},
  doi       = {10.18653/v1/2025.cl4health-1.23},
  pages     = {269--284},
  isbn      = {979-8-89176-238-1},
  abstract  = {Health literacy enables individuals to navigate healthcare systems and make informed decisions. Plain language summaries (PLS) can bridge comprehension gaps by simplifying complex biomedical texts, yet their manual creation is both time-consuming and challenging. This study advances the field by (1) constructing a novel corpus of paired technical and plain language texts from medical trial libraries, (2) developing machine learning classifiers to rapidly identify plain language features, and (3) establishing a multi-dimensional evaluation framework that integrates computational metrics with human expertise. We iteratively optimized prompts for diverse large language models (LLMs)—including GPT models, Gemini 1.5, DeepSeek-R1, and Llama-3.2—to generate PLS variants aligned with domain-specific guidelines. Our classifier achieved 97.5% accuracy in distinguishing plain from technical language, and the generated summaries demonstrated high semantic equivalence to expert-written versions.},
  selected  = {true}
}

@misc{penuela2025guidingmultimodallargelanguage,
  title         = {Guiding Multimodal Large Language Models with Blind and Low Vision People Visual Questions for Proactive Visual Interpretations},
  author        = {Ricardo Gonzalez Penuela and Felipe Arias-Russi and Victor Capriles},
  year          = {2025},
  eprint        = {2510.01576},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/2510.01576}
}

@misc{ariasrussi2025cariscontextadaptablerobotinterface,
  title         = {CARIS: A Context-Adaptable Robot Interface System for Personalized and Scalable Human-Robot Interaction},
  author        = {Felipe Arias-Russi and Yuanchen Bai and Angelique Taylor},
  year          = {2025},
  eprint        = {2509.00660},
  archiveprefix = {arXiv},
  primaryclass  = {cs.RO},
  url           = {https://arxiv.org/abs/2509.00660}
}